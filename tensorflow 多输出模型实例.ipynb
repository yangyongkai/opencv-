{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset/多输出训练模型数据集'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_path = list(data_root.glob('*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset\\\\多输出训练模型数据集\\\\black_jeans\\\\00000000.jpg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\black_jeans\\\\00000001.jpeg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\black_jeans\\\\00000002.jpeg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\black_jeans\\\\00000003.jpg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\black_jeans\\\\00000004.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_path = [str(path) for path in all_image_path]\n",
    "all_image_path[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset\\\\多输出训练模型数据集\\\\red_dress\\\\00000333.jpg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\blue_jeans\\\\00000086.jpg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\red_dress\\\\00000114.jpg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\black_jeans\\\\00000351.jpg',\n",
       " 'dataset\\\\多输出训练模型数据集\\\\blue_shirt\\\\00000011.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(all_image_path)\n",
    "all_image_path[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black_jeans',\n",
       " 'black_shoes',\n",
       " 'blue_dress',\n",
       " 'blue_jeans',\n",
       " 'blue_shirt',\n",
       " 'red_dress',\n",
       " 'red_shirt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name = sorted(item.name for item in data_root.glob('*/'))\n",
    "label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'black', 'blue', 'red'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_label_names = set(name.split('_')[0] for name in label_name)\n",
    "color_label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress', 'jeans', 'shirt', 'shoes'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_label_names = set(name.split('_')[1] for name in label_name)\n",
    "item_label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'red': 0, 'black': 1, 'blue': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_label_to_index = dict((name, index) for index, name in enumerate(color_label_names))\n",
    "color_label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 0, 'shoes': 1, 'jeans': 2, 'shirt': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_label_to_index = dict((name, index) for index, name in enumerate(item_label_names))\n",
    "item_label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red_dress', 'blue_jeans', 'red_dress', 'black_jeans', 'blue_shirt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_labels = [pathlib.Path(path).parent.name for path in all_image_path]\n",
    "all_image_labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 0, 1, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_label = [color_label_to_index[label.split('_')[0]] for label in all_image_labels]\n",
    "color_label[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 0, 2, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_label = [item_label_to_index[label.split('_')[1]] for label in all_image_labels]\n",
    "item_label[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224,224])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(all_image_path)\n",
    "path_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (224, 224, 3), types: tf.float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ds = path_ds.map(load_and_preprocess_image)\n",
    "image_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ds = tf.data.Dataset.from_tensor_slices((color_label, item_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "2 2\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "for e in label_ds.take(3):\n",
    "    print(e[0].numpy(), e[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((224, 224, 3), ((), ())), types: (tf.float32, (tf.int32, tf.int32))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "image_label_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(all_image_path)\n",
    "test_count = int(image_count*0.2)\n",
    "train_count = image_count-test_count\n",
    "\n",
    "train_data = image_label_ds.skip(test_count)\n",
    "test_data = image_label_ds.take(test_count)\n",
    "\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 224, 224, 3), ((None,), (None,))), types: (tf.float32, (tf.int32, tf.int32))>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.shuffle(buffer_size=train_count).repeat(-1)\n",
    "train_data =train_data.batch(BATCH_SIZE)\n",
    "test_data = test_data.batch(BATCH_SIZE)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
    "                                               include_top = False,\n",
    "                                               weights='imagenet') #加载预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_net.trianable = False #设置不可训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mobile_net(inputs)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x1 = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "out_color = tf.keras.layers.Dense(len(color_label_names), \n",
    "                                  activation='softmax',\n",
    "                                  name='out_color')(x1)\n",
    "x2 = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "out_item = tf.keras.layers.Dense(len(item_label_names), \n",
    "                                 activation='softmax',\n",
    "                                 name='out_item')(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = inputs,\n",
    "                       outputs = [out_color, out_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Model)    (None, 7, 7, 1280)   2257984     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           mobilenetv2_1.00_224[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1311744     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         1311744     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "out_color (Dense)               (None, 3)            3075        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "out_item (Dense)                (None, 4)            4100        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,888,647\n",
      "Trainable params: 4,854,535\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "              loss={'out_color':'sparse_categorical_crossentropy',\n",
    "                    'out_item':'sparse_categorical_crossentropy',},\n",
    "              metrics=['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_steps = train_count//BATCH_SIZE\n",
    "test_steps = test_count//BATCH_SIZE\n",
    "test_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 126 steps, validate for 31 steps\n",
      "Epoch 1/5\n",
      "126/126 [==============================] - 72s 568ms/step - loss: 0.0542 - out_color_loss: 0.0311 - out_item_loss: 0.0232 - out_color_acc: 0.9891 - out_item_acc: 0.9936 - val_loss: 0.1572 - val_out_color_loss: 0.0858 - val_out_item_loss: 0.0714 - val_out_color_acc: 0.9758 - val_out_item_acc: 0.9758\n",
      "Epoch 2/5\n",
      "126/126 [==============================] - 69s 546ms/step - loss: 0.0612 - out_color_loss: 0.0278 - out_item_loss: 0.0334 - out_color_acc: 0.9901 - out_item_acc: 0.9921 - val_loss: 0.1087 - val_out_color_loss: 0.0503 - val_out_item_loss: 0.0584 - val_out_color_acc: 0.9819 - val_out_item_acc: 0.9819\n",
      "Epoch 3/5\n",
      "126/126 [==============================] - 70s 555ms/step - loss: 0.0394 - out_color_loss: 0.0256 - out_item_loss: 0.0137 - out_color_acc: 0.9926 - out_item_acc: 0.9945 - val_loss: 0.1422 - val_out_color_loss: 0.0714 - val_out_item_loss: 0.0708 - val_out_color_acc: 0.9798 - val_out_item_acc: 0.9819\n",
      "Epoch 4/5\n",
      "126/126 [==============================] - 70s 554ms/step - loss: 0.0341 - out_color_loss: 0.0257 - out_item_loss: 0.0083 - out_color_acc: 0.9931 - out_item_acc: 0.9965 - val_loss: 0.2717 - val_out_color_loss: 0.0918 - val_out_item_loss: 0.1799 - val_out_color_acc: 0.9698 - val_out_item_acc: 0.9435\n",
      "Epoch 5/5\n",
      "126/126 [==============================] - 71s 566ms/step - loss: 0.0527 - out_color_loss: 0.0351 - out_item_loss: 0.0176 - out_color_acc: 0.9866 - out_item_acc: 0.9931 - val_loss: 0.0400 - val_out_color_loss: 0.0259 - val_out_item_loss: 0.0140 - val_out_color_acc: 0.9940 - val_out_item_acc: 0.9940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                   epochs=5,\n",
    "                   steps_per_epoch=train_steps,\n",
    "                   validation_data=test_data,\n",
    "                   validation_steps=test_steps\n",
    "         ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.009910398162901402, 0.004384175, 0.005526223, 1.0, 1.0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate( test_data,verbose=0,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

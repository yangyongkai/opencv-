{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import operator\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义画图函数\n",
    "def cv_show(name, img):\n",
    "    cv.imshow(name, img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取从视频中截取的图像\n",
    "image = cv.imread(r'D:\\opencv-ziliao\\park\\test_images\\scene1410.jpg')\n",
    "cv_show('image', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#掩膜以去除背景\n",
    "\n",
    "# 制作mask\n",
    "lower = np.uint8([120, 120, 120])\n",
    "upper = np.uint8([255, 255, 255])\n",
    "# lower_red和高于upper_red的部分分别变成0，lower_red～upper_red之间的值变成255,相当于过滤背景\n",
    "white_mask = cv.inRange(image, lower, upper)\n",
    "cv_show('white_mask',white_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与操作去除背景\n",
    "white_yellow_image = cv.bitwise_and(image, image, mask = white_mask)\n",
    "cv_show('white_yellow_image', white_yellow_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转灰度图\n",
    "gray_image = cv.cvtColor(white_yellow_image, cv.COLOR_BGR2GRAY)\n",
    "cv_show('gray_image', gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 边缘检测\n",
    "edge_image = cv.Canny(gray_image, 50, 200)\n",
    "cv_show('edge_image', edge_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 手动选择停车场区域\n",
    "# 在停车场区域周围做几个标记来将此区域围起来\n",
    "row, col = image.shape[:2]\n",
    "pt_1 = [col*0.05, row*0.90]\n",
    "pt_2 = [col*0.05, row*0.70]\n",
    "pt_3 = [col*0.30, row*0.55]\n",
    "pt_4 = [col*0.6, row*0.15]\n",
    "pt_5 = [col*0.90, row*0.15] \n",
    "pt_6 = [col*0.90, row*0.90]\n",
    "\n",
    "vertices = np.array([[pt_1, pt_2, pt_3, pt_4, pt_5, pt_6]], dtype=np.int32)\n",
    "point_img = edge_image.copy()\n",
    "point_img = cv.cvtColor(point_img, cv.COLOR_GRAY2RGB)\n",
    "for point in vertices[0]:\n",
    "    cv.circle(point_img, (point[0], point[1]), 10, (0, 0, 255), 4)\n",
    "cv_show('point_img', point_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这几个红色圆圈所包围的地方做一个mask\n",
    "mask = np.zeros_like(edge_image)\n",
    "cv.fillPoly(mask, vertices, 255)\n",
    "cv_show('mask', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤操作，删除居民楼等区域\n",
    "roi_image = cv.bitwise_and(edge_image, mask)\n",
    "cv_show('roi_image', roi_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2169, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# 霍夫变换检测直线\n",
    "lines = cv.HoughLinesP(roi_image, rho=0.1, theta=np.pi/10, threshold=15, minLineLength=9, maxLineGap=4)\n",
    "print(lines.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No lines detected:  559\n"
     ]
    }
   ],
   "source": [
    "# 挑出符合要求的直线并画出\n",
    "line_image = np.copy(image)\n",
    "cleaned = []\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    if abs(y2-y1) <= 1 and abs(x2-x1) >=25 and abs(x2-x1) <= 55:\n",
    "        cleaned.append((x1, y1, x2, y2))\n",
    "        cv.line(line_image, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "print(\"No lines detected: \", len(cleaned))\n",
    "cv_show('line_image', line_image)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按列划分区域\n",
    "\n",
    "# 将得到的直线cleaned进行排序\n",
    "# 由于得到的列表中的直线没有顺序，所以要先进行排序，排序原则：x1越来越大，x1相同的情况下，y1越来越大。\n",
    "rect_image = np.copy(image)\n",
    "list1 = sorted(cleaned, key=operator.itemgetter(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将在同一列的直线放到字典中的一个键中\n",
    "\n",
    "clusters = {}\n",
    "dIndex = 0\n",
    "clus_dist = 20\n",
    "for i in range(len(list1) - 1):\n",
    "    distance = abs(list1[i+1][0] - list1[i][0])\n",
    "    if distance <= clus_dist:\n",
    "        if not dIndex in clusters.keys(): \n",
    "            clusters[dIndex] = []\n",
    "        clusters[dIndex].append(list1[i])\n",
    "        clusters[dIndex].append(list1[i + 1]) \n",
    "\n",
    "    else:\n",
    "        dIndex += 1\n",
    "#得到含有键值为0-11的字典clusters。clusters中的每个键代表一列区域中的所有直线的端点坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Parking Lanes:  12\n"
     ]
    }
   ],
   "source": [
    "# 得到矩形坐标\n",
    "# set()去重。 排序。一列中至少有5条直线\n",
    "# 纵坐标 = 一列中上下两边界的纵坐标，横坐标 = 列中所有直线两端点坐标平均值\n",
    "\n",
    "rect_coord = {}\n",
    "i = 0\n",
    "for key in clusters:\n",
    "    all_list = clusters[key]\n",
    "    list2 = list(set(all_list))\n",
    "    if len(list2) > 5:\n",
    "        list2 = sorted(list2, key=lambda tup: tup[1])\n",
    "        avg_y1 = list2[0][1]\n",
    "        avg_y2 = list2[-1][1]\n",
    "        avg_x1 = 0\n",
    "        avg_x2 = 0\n",
    "        for tup in list2:\n",
    "            avg_x1 += tup[0]\n",
    "            avg_x2 += tup[2]\n",
    "        avg_x1 = avg_x1/len(list2)\n",
    "        avg_x2 = avg_x2/len(list2)\n",
    "        rect_coord[i] = (avg_x1, avg_y1, avg_x2, avg_y2)\n",
    "        i += 1\n",
    "print(\"Num Parking Lanes: \", len(rect_coord))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "buff = 7  # 微调\n",
    "for key in rect_coord:\n",
    "    tup_topLeft = (int(rect_coord[key][0] - buff), int(rect_coord[key][1]))\n",
    "    tup_botRight = (int(rect_coord[key][2] + buff), int(rect_coord[key][3]))\n",
    "    cv.rectangle(rect_image, tup_topLeft,tup_botRight,(0,255,0),3)\n",
    "cv_show('rect_image', rect_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total parking spaces:  561 560\n"
     ]
    }
   ],
   "source": [
    "# 在每个列区域画出横线\n",
    "delineated = np.copy(image)\n",
    "gap = 15.5  # 同一列中相邻停车位之间的纵向距离\n",
    "spot_pos = {}\n",
    "tot_spots = 0\n",
    "#微调\n",
    "adj_y1 = {0: 20, 1:-10, 2:0, 3:-11, 4:28, 5:5, 6:-15, 7:-15, 8:-10, 9:-30, 10:9, 11:-32}\n",
    "adj_y2 = {0: 30, 1: 50, 2:15, 3:10, 4:-15, 5:15, 6:15, 7:-20, 8:15, 9:15, 10:0, 11:30}\n",
    "\n",
    "adj_x1 = {0: -8, 1:-15, 2:-15, 3:-15, 4:-15, 5:-15, 6:-15, 7:-15, 8:-10, 9:-10, 10:-10, 11:0}\n",
    "adj_x2 = {0: 0, 1: 15, 2:15, 3:15, 4:15, 5:15, 6:15, 7:15, 8:10, 9:10, 10:10, 11:0}\n",
    "\n",
    "\n",
    "for key in rect_coord:\n",
    "    tup = rect_coord[key]\n",
    "    x1 = int(tup[0] + adj_x1[key])\n",
    "    x2 = int(tup[2] + adj_x2[key])\n",
    "    y1 = int(tup[1] + adj_y1[key])\n",
    "    y2 = int(tup[3] + adj_y2[key])\n",
    "    cv.rectangle(delineated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    num_splits = int(abs(y2-y1) // gap)\n",
    "    for i in range(num_splits + 1):\n",
    "        y = int(y1 + i * gap)\n",
    "        cv.line(delineated, (x1, y), (x2, y), [255, 0, 0], 2)\n",
    "    if key > 0 and key < len(rect_coord) - 1:\n",
    "        x = int((x1 + x2) / 2)\n",
    "        cv.line(delineated, (x, y1), (x, y2), [255, 0, 0], 2)\n",
    "    if key == 0 or key == (len(rect_coord) - 1):\n",
    "        tot_spots += num_splits + 1\n",
    "    else:\n",
    "        tot_spots += 2 * (num_splits + 1)\n",
    "    if key == 0 or key == (len(rect_coord) - 1):\n",
    "        for i in range(num_splits + 1):\n",
    "            cur_len = len(spot_pos)\n",
    "            y = int(y1 + i * gap)\n",
    "            spot_pos[(x1, y, x2, y+gap)] = cur_len + 1\n",
    "    else:\n",
    "        for i in range(num_splits + 1):\n",
    "            cur_len = len(spot_pos)\n",
    "            y = int(y1 + i * gap)\n",
    "            x = int((x1 + x2) / 2)\n",
    "            spot_pos[(x1, y, x, y+gap)] = cur_len +1\n",
    "            spot_pos[(x, y, x2, y+gap)] = cur_len +2 \n",
    "print(\"total parking spaces: \", tot_spots, cur_len)\n",
    "cv_show('delineated', delineated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将得到的每个停车位的位置信息写入文件\n",
    "with open('spot_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(spot_pos, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将得到的每个停车位裁剪下来做成样本\n",
    "for spot in spot_pos:\n",
    "    (x1, y1, x2, y2) = spot\n",
    "    (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2))\n",
    "    #裁剪\n",
    "    spot_img = image[y1:y2, x1:x2]\n",
    "    spot_img = cv.resize(spot_img, (0,0), fx=2.0, fy=2.0) \n",
    "    spot_id = spot_pos[spot]\n",
    "    filename = 'spot' + str(spot_id) +'.jpg'\n",
    "#     print(spot_img.shape, filename, (x1,x2,y1,y2))\n",
    "    cv.imwrite(os.path.join('D:\\Jupyter\\dataset\\cnn_data', filename), spot_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('car1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('D:\\Jupyter\\dataset\\cnn_data\\*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.sort(key=lambda a:int(a.split('\\\\')[-1].split('t')[1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = tf.data.Dataset.from_tensor_slices(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [48, 48])\n",
    "    img = tf.cast(img, tf.float32)\n",
    "#     img = img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = image_dataset.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = image_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\Jupyter\\spot_dict.pickle', 'rb') as f:\n",
    "    spot_pos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dictionary = {}\n",
    "class_dictionary[0] = 'empty'\n",
    "class_dictionary[1] = 'occupied'\n",
    "predicted_images = np.copy(image)\n",
    "overlay = np.copy(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i,img in enumerate(image_dataset):\n",
    "    class_predicted = model.predict(img)\n",
    "    inID = np.argmax(class_predicted[0])\n",
    "    label = class_dictionary[inID]\n",
    "    if label == 'empty':\n",
    "        for key in spot_pos:\n",
    "            if spot_pos[key] == i+1:\n",
    "                (x1, y1, x2, y2) = key\n",
    "                cv.rectangle(overlay, (int(x1),int(y1)), (int(x2),int(y2)), [0, 255, 0], -1)\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "predicted_images = cv.addWeighted(overlay, alpha, predicted_images, 1 - alpha, 0, predicted_images)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_show('predicted_images', predicted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对录像视频进行测试，实时识别出空停车位位置及数量\n",
    "\n",
    "video_name = 'D:\\opencv-ziliao\\park\\parking_video.mp4'\n",
    "cap = cv.VideoCapture(video_name)\n",
    "count = 0\n",
    "while 1:\n",
    "    ret, image = cap.read()\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        count = 0\n",
    "        \n",
    "        new_image = np.copy(image)\n",
    "        overlay = np.copy(image)\n",
    "        cnt_empty = 0\n",
    "        all_spots = 0\n",
    "        color = [0, 255, 0]\n",
    "        alpha = 0.5\n",
    "        for i,img in enumerate(image_dataset):\n",
    "            class_predicted = model.predict(img)\n",
    "            inID = np.argmax(class_predicted[0])\n",
    "            label = class_dictionary[inID]\n",
    "            if label == 'empty':\n",
    "                for key in spot_pos:\n",
    "                    if spot_pos[key] == i+1:\n",
    "                        (x1, y1, x2, y2) = key\n",
    "                        cv.rectangle(overlay, (int(x1),int(y1)), (int(x2),int(y2)), color, -1)\n",
    "                        cnt_empty += 1\n",
    "        cv.addWeighted(overlay, alpha, new_image, 1 - alpha, 0, new_image)\n",
    "        cv.putText(new_image, \"Available: %d spots\" %cnt_empty, (30, 95),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7, (255, 255, 255), 2)\n",
    "\n",
    "        cv.putText(new_image, \"Total: %d spots\" %all_spots, (30, 125),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7, (255, 255, 255), 2)\n",
    "        cv.imshow('frame', new_image)\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[281,271,57,7],[374,270,65,65]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(x[0][0]*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[323,295,58,58]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
